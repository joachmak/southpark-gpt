{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a627eace-268e-4321-9b5e-4c66eb42edc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59915119-12ea-460b-a93c-099d55a341be",
   "metadata": {},
   "source": [
    "### Get real script lines for each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d7687b-9d6e-4360-9109-211317f177b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_str_script_from_df(df):\n",
    "    # convert df into a string episode script\n",
    "    df = df.iloc[:, 2:].fillna('<scene>')\n",
    "    \n",
    "    # Concatenate the remaining columns into a single string for each row\n",
    "    df['formatted_string'] = df.apply(lambda row: ': '.join(row.astype(str)), axis=1)\n",
    "    \n",
    "    # Combine all rows into a single string separated by line breaks\n",
    "    final_string = '\\n'.join(df['formatted_string'])\n",
    "    return final_string.replace(\"\\'\", \"`\").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fb18865-2c83-47a4-8f55-56fcaf1e415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season 8!\n",
      "Season 9!\n",
      "Season 10!\n",
      "Season 11!\n",
      "Season 12!\n"
     ]
    }
   ],
   "source": [
    "SEASONS = [8,9,10,11,12]\n",
    "CHARACTERS = [\"stan\", \"kyle\", \"cartman\", \"butters\"]\n",
    "\n",
    "cartman_data = []\n",
    "stan_data = []\n",
    "kyle_data = []\n",
    "butters_data = []\n",
    "\n",
    "for SEASON in SEASONS:\n",
    "    # get all .csv files in correct season dir\n",
    "    episodes = list(filter(lambda file: file[-4:] == \".csv\", os.listdir(os.path.join(\".\", \"episodes_csv\", f\"s{SEASON}\"))))\n",
    "    print(f\"Season {SEASON}!\")\n",
    "    for episode in episodes:\n",
    "        df = pd.read_csv(os.path.join(\".\", \"episodes_csv\", f\"s{SEASON}\", episode), delimiter=';', header=None)\n",
    "        str_script = get_str_script_from_df(df)\n",
    "\n",
    "        lines = str_script.split(\"\\n\")\n",
    "        \n",
    "        for line in lines:\n",
    "            try:\n",
    "                split_line = line.split(\": \")\n",
    "                character = split_line[0]\n",
    "                char_line = split_line[1]\n",
    "                \n",
    "                if character not in CHARACTERS:\n",
    "                    continue\n",
    "                    \n",
    "                if character == \"cartman\":\n",
    "                    cartman_data.append(char_line)\n",
    "                elif character == \"stan\":\n",
    "                    stan_data.append(char_line)\n",
    "                elif character == \"kyle\":\n",
    "                    kyle_data.append(char_line)\n",
    "                elif character == \"butters\":\n",
    "                    butters_data.append(char_line)\n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f125f2-ad85-48d5-bff8-e5d8a12cd01a",
   "metadata": {},
   "source": [
    "### Get generated script lines for each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbf953dc-2c26-46fa-a496-a9a63e35a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_eps_path = os.path.join(\".\", \"gen_eps\")\n",
    "dirs = list(filter(lambda filename: filename[0] == \"2\", os.listdir(gen_eps_path)))\n",
    "\n",
    "cartman_data_gen = []\n",
    "stan_data_gen = []\n",
    "kyle_data_gen = []\n",
    "butters_data_gen = []\n",
    "\n",
    "for dir in dirs:\n",
    "    file = os.path.join(gen_eps_path, dir, \"ep.txt\")\n",
    "    with open(file, \"r\") as f:\n",
    "        script = f.read()\n",
    "    lines = script.split(\"\\n\")\n",
    "    for line in lines:\n",
    "        split_line = line.split(\": \")\n",
    "        if len(split_line) < 2:\n",
    "            continue\n",
    "        character = split_line[0]\n",
    "        char_line = split_line[1]\n",
    "\n",
    "        if character == \"cartman\":\n",
    "            cartman_data_gen.append(char_line)\n",
    "        elif character == \"stan\":\n",
    "            stan_data_gen.append(char_line)\n",
    "        elif character == \"butters\":\n",
    "            butters_data_gen.append(char_line)\n",
    "        elif character == \"kyle\":\n",
    "            kyle_data_gen.append(char_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51b3f1a6-34db-414b-bebe-676ff7b5a228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "butters: 76, stan: 194, cartman: 301, kyle: 67\n"
     ]
    }
   ],
   "source": [
    "print(f\"butters: {len(butters_data_gen)}, stan: {len(stan_data_gen)}, cartman: {len(cartman_data_gen)}, kyle: {len(kyle_data_gen)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6df0ea12-b483-4f65-92c9-30efffe75237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess_text(txt: str):\n",
    "    txt = txt.lower()\n",
    "    # remove punctuation\n",
    "    txt = re.sub(r'[^\\w\\s]','',txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14968c4e-1d48-4b7c-a3b2-cb03c40dd09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/joachimmaksim/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b8ebb5d7-14d4-45c5-8f49-969020b14dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def find_average_sentence_length(txt: str):\n",
    "    sentences = sent_tokenize(txt) \n",
    "    sentence_lengths = list(map(lambda s: len(s), sentences))\n",
    "    return sum(sentence_lengths) / len(sentence_lengths)\n",
    "\n",
    "def find_average_word_length(txt: str):\n",
    "    words = txt.split(\" \")\n",
    "    word_lengths = list(map(lambda w: len(w), words))\n",
    "    return sum(word_lengths) / len(word_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5665bc7d-780f-4ca2-9c45-20bd46414e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence length (gen / real) = \t38.266129032258064 / 41.048050139275766 = 0.9322276917520159\n",
      "word length (gen / real) = \t3.9554347826086955 / 4.072424407025167 \t= 0.9712727327204262\n",
      "gen Butters similarity to butters (rouge-1 precision):\n",
      "0.816304347826087\n",
      "gen Cartman similarity to butters (rouge-1 precision):\n",
      "0.7084901030590545\n",
      "gen Kyle similarity to butters (rouge-1 precision):\n",
      "0.776685393258427\n",
      "gen Stan similarity to butters (rouge-1 precision):\n",
      "0.7957911145752143\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=False)\n",
    "\n",
    "butters_gen_combined = \" \".join(butters_data_gen)\n",
    "cartman_gen_combined = \" \".join(cartman_data_gen)\n",
    "stan_gen_combined = \" \".join(stan_data_gen)\n",
    "kyle_gen_combined = \" \".join(kyle_data_gen)\n",
    "\n",
    "butters_combined = \" \".join(butters_data)\n",
    "\n",
    "\n",
    "gen_sentence_len = find_average_sentence_length(butters_gen_combined)\n",
    "real_sentence_len = find_average_sentence_length(butters_combined)\n",
    "print(f\"sentence length (gen / real) = \\t{gen_sentence_len} / {real_sentence_len} = {gen_sentence_len / real_sentence_len}\")\n",
    "\n",
    "gen_word_len = find_average_word_length(preprocess_text(butters_gen_combined))\n",
    "real_word_len = find_average_word_length(preprocess_text(butters_combined))\n",
    "print(f\"word length (gen / real) = \\t{gen_word_len} / {real_word_len} \\t= {gen_word_len / real_word_len}\")\n",
    "\n",
    "print(\"gen Butters similarity to butters (rouge-1 precision):\")\n",
    "print(scorer.score(preprocess_text(butters_combined), preprocess_text(butters_gen_combined))[\"rouge1\"].precision)\n",
    "\n",
    "print(\"gen Cartman similarity to butters (rouge-1 precision):\")\n",
    "print(scorer.score(preprocess_text(butters_combined), preprocess_text(cartman_gen_combined))[\"rouge1\"].precision)\n",
    "\n",
    "print(\"gen Kyle similarity to butters (rouge-1 precision):\")\n",
    "print(scorer.score(preprocess_text(butters_combined), preprocess_text(kyle_gen_combined))[\"rouge1\"].precision)\n",
    "\n",
    "print(\"gen Stan similarity to butters (rouge-1 precision):\")\n",
    "print(scorer.score(preprocess_text(butters_combined), preprocess_text(stan_gen_combined))[\"rouge1\"].precision)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
