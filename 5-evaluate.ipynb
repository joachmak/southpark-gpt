{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a627eace-268e-4321-9b5e-4c66eb42edc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59915119-12ea-460b-a93c-099d55a341be",
   "metadata": {},
   "source": [
    "### Get real script lines for each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8d7687b-9d6e-4360-9109-211317f177b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_str_script_from_df(df):\n",
    "    # convert df into a string episode script\n",
    "    df = df.iloc[:, 2:].fillna('<scene>')\n",
    "    \n",
    "    # Concatenate the remaining columns into a single string for each row\n",
    "    df['formatted_string'] = df.apply(lambda row: ': '.join(row.astype(str)), axis=1)\n",
    "    \n",
    "    # Combine all rows into a single string separated by line breaks\n",
    "    final_string = '\\n'.join(df['formatted_string'])\n",
    "    return final_string.replace(\"\\'\", \"`\").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9fb18865-2c83-47a4-8f55-56fcaf1e415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season 8!\n",
      "Season 9!\n",
      "Season 10!\n",
      "Season 11!\n",
      "Season 12!\n",
      "Season 13!\n",
      "Season 14!\n",
      "Season 15!\n"
     ]
    }
   ],
   "source": [
    "SEASONS = [8,9,10,11,12,13,14,15]\n",
    "CHARACTERS = [\"stan\", \"kyle\", \"cartman\", \"butters\"]\n",
    "\n",
    "cartman_data = []\n",
    "stan_data = []\n",
    "kyle_data = []\n",
    "butters_data = []\n",
    "\n",
    "for SEASON in SEASONS:\n",
    "    # get all .csv files in correct season dir\n",
    "    episodes = list(filter(lambda file: file[-4:] == \".csv\", os.listdir(os.path.join(\".\", \"episodes_csv\", f\"s{SEASON}\"))))\n",
    "    print(f\"Season {SEASON}!\")\n",
    "    for episode in episodes:\n",
    "        df = pd.read_csv(os.path.join(\".\", \"episodes_csv\", f\"s{SEASON}\", episode), delimiter=';', header=None)\n",
    "        str_script = get_str_script_from_df(df)\n",
    "\n",
    "        lines = str_script.split(\"\\n\")\n",
    "        \n",
    "        for line in lines:\n",
    "            try:\n",
    "                split_line = line.split(\": \")\n",
    "                character = split_line[0]\n",
    "                char_line = split_line[1]\n",
    "                \n",
    "                if character not in CHARACTERS:\n",
    "                    continue\n",
    "                    \n",
    "                if character == \"cartman\":\n",
    "                    cartman_data.append(char_line)\n",
    "                elif character == \"stan\":\n",
    "                    stan_data.append(char_line)\n",
    "                elif character == \"kyle\":\n",
    "                    kyle_data.append(char_line)\n",
    "                elif character == \"butters\":\n",
    "                    butters_data.append(char_line)\n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f125f2-ad85-48d5-bff8-e5d8a12cd01a",
   "metadata": {},
   "source": [
    "### Get generated script lines for each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbf953dc-2c26-46fa-a496-a9a63e35a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eps_from_dir(dirpath: str):\n",
    "    dirs = list(filter(lambda filename: filename[0] == \"2\", os.listdir(dirpath)))\n",
    "    \n",
    "    cartman = []\n",
    "    stan = []\n",
    "    kyle = []\n",
    "    butters = []\n",
    "    \n",
    "    for dir in dirs:\n",
    "        try:\n",
    "            file = os.path.join(dirpath, dir, \"ep.txt\")\n",
    "            with open(file, \"r\") as f:\n",
    "                script = f.read()\n",
    "        except:\n",
    "            continue\n",
    "        lines = script.split(\"\\n\")\n",
    "        for line in lines:\n",
    "            split_line = line.split(\": \")\n",
    "            if len(split_line) < 2:\n",
    "                continue\n",
    "            character = split_line[0]\n",
    "            char_line = \" \".join(split_line[1:])\n",
    "    \n",
    "            if character == \"cartman\":\n",
    "                cartman.append(char_line)\n",
    "            elif character == \"stan\":\n",
    "                stan.append(char_line)\n",
    "            elif character == \"butters\":\n",
    "                butters.append(char_line)\n",
    "            elif character == \"kyle\":\n",
    "                kyle.append(char_line)\n",
    "    return \" \".join(cartman), \" \".join(stan), \" \".join(kyle), \" \".join(butters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6df0ea12-b483-4f65-92c9-30efffe75237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess_text(txt: str):\n",
    "    txt = txt.lower()\n",
    "    # remove punctuation\n",
    "    txt = re.sub(r'[^\\w\\s]','',txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14968c4e-1d48-4b7c-a3b2-cb03c40dd09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/joachimmaksim/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b8ebb5d7-14d4-45c5-8f49-969020b14dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def find_average_sentence_length(txt: str):\n",
    "    sentences = sent_tokenize(txt) \n",
    "    sentence_lengths = list(map(lambda s: len(s), sentences))\n",
    "    return sum(sentence_lengths) / len(sentence_lengths)\n",
    "\n",
    "def find_average_word_length(txt: str):\n",
    "    words = txt.split(\" \")\n",
    "    word_lengths = list(map(lambda w: len(w), words))\n",
    "    return sum(word_lengths) / len(word_lengths)\n",
    "\n",
    "def find_rouge_score(generated: str, target: str):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=False)\n",
    "    return scorer.score(preprocess_text(target), preprocess_text(generated))[\"rouge1\"].precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ea539d67-973a-4538-996a-ea911a25be44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the various types of datasets\n",
    "tuned_cartman, tuned_stan, tuned_kyle, tuned_butters = get_eps_from_dir(\"gen_eps\")\n",
    "untuned_cartman, untuned_stan, untuned_kyle, untuned_butters = get_eps_from_dir(\"gen_eps_untuned\")\n",
    "untuned_cartman_m, untuned_stan_m, untuned_kyle_m, untuned_butters_m = get_eps_from_dir(\"gen_eps_untuned_tuned_manager\")\n",
    "\n",
    "real_cartman = \" \".join(cartman_data)\n",
    "real_stan = \" \".join(stan_data)\n",
    "real_kyle = \" \".join(kyle_data)\n",
    "real_butters = \" \".join(butters_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3067a18c-f48d-42e8-b037-19709762ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sentence_lengths(gen: str, real: str):\n",
    "    gen_len = find_average_sentence_length(gen)\n",
    "    gen_real = find_average_sentence_length(real)\n",
    "    print(f\"Sentence length:\\tgen / real = \\t{gen_len / gen_real}\")\n",
    "\n",
    "def compare_word_lengths(gen: str, real: str):\n",
    "    gen_len = find_average_word_length(gen)\n",
    "    gen_real = find_average_word_length(real)\n",
    "    print(f\"Word length:\\t\\tgen / real =  \\t{gen_len / gen_real}\")\n",
    "\n",
    "def compare_rouge(gen: str, real: str):\n",
    "    rouge = find_rouge_score(gen, real)\n",
    "    print(f\"rouge-1 precision:\\t\\t\\t{rouge}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "adde9697-1386-4f7e-abb8-77f9d0606af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_char_ratings(char_name: str, tuned, untuned, untuned_m, real):\n",
    "    print(f\"===== \\t {char_name} \\t=========\")\n",
    "    # === tuned ===\n",
    "    print(\"\\nTuned\")\n",
    "    compare_sentence_lengths(tuned, real)\n",
    "    compare_word_lengths(tuned, real)\n",
    "    compare_rouge(tuned, real)\n",
    "    \n",
    "    # === untuned with tuned manager ===\n",
    "    print(\"\\nUntuned with tuned manager\")\n",
    "    compare_sentence_lengths(untuned_m, real)\n",
    "    compare_word_lengths(untuned_m, real)\n",
    "    compare_rouge(untuned_m, real)\n",
    "    \n",
    "    # === untuned ===\n",
    "    print(\"\\nUntuned\")\n",
    "    compare_sentence_lengths(untuned, real)\n",
    "    compare_word_lengths(untuned, real)\n",
    "    compare_rouge(untuned, real) \n",
    "    print()\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c5343de4-6cfb-4b26-8293-b023653a12b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== \t Cartman \t=========\n",
      "\n",
      "Tuned\n",
      "Sentence length:\tgen / real = \t1.0931909176419095\n",
      "Word length:\t\tgen / real =  \t1.0163174831817068\n",
      "rouge-1 precision:\t\t\t0.8647144948755491\n",
      "\n",
      "Untuned with tuned manager\n",
      "Sentence length:\tgen / real = \t1.2775439856649602\n",
      "Word length:\t\tgen / real =  \t1.0030567064696565\n",
      "rouge-1 precision:\t\t\t0.8818529536761581\n",
      "\n",
      "Untuned\n",
      "Sentence length:\tgen / real = \t1.3543604513905285\n",
      "Word length:\t\tgen / real =  \t1.002887596010105\n",
      "rouge-1 precision:\t\t\t0.8967551622418879\n",
      "\n",
      "\n",
      "===== \t Stan \t=========\n",
      "\n",
      "Tuned\n",
      "Sentence length:\tgen / real = \t0.9330047601018663\n",
      "Word length:\t\tgen / real =  \t1.0333306727280516\n",
      "rouge-1 precision:\t\t\t0.8901918976545842\n",
      "\n",
      "Untuned with tuned manager\n",
      "Sentence length:\tgen / real = \t2.0842729652773797\n",
      "Word length:\t\tgen / real =  \t1.082709450996585\n",
      "rouge-1 precision:\t\t\t0.8901098901098901\n",
      "\n",
      "Untuned\n",
      "Sentence length:\tgen / real = \t1.4975630245218536\n",
      "Word length:\t\tgen / real =  \t1.0162948568702237\n",
      "rouge-1 precision:\t\t\t0.8991150442477877\n",
      "\n",
      "\n",
      "===== \t Kyle \t=========\n",
      "\n",
      "Tuned\n",
      "Sentence length:\tgen / real = \t0.8135249533686606\n",
      "Word length:\t\tgen / real =  \t1.0126461966784284\n",
      "rouge-1 precision:\t\t\t0.8881829733163914\n",
      "\n",
      "Untuned with tuned manager\n",
      "Sentence length:\tgen / real = \t1.4261277791254072\n",
      "Word length:\t\tgen / real =  \t1.0108337287081717\n",
      "rouge-1 precision:\t\t\t0.8832116788321168\n",
      "\n",
      "Untuned\n",
      "Sentence length:\tgen / real = \t1.6375344765420725\n",
      "Word length:\t\tgen / real =  \t0.9945672103983593\n",
      "rouge-1 precision:\t\t\t0.880201765447667\n",
      "\n",
      "\n",
      "===== \t Butters \t=========\n",
      "\n",
      "Tuned\n",
      "Sentence length:\tgen / real = \t0.909960240849898\n",
      "Word length:\t\tgen / real =  \t0.9651113965321346\n",
      "rouge-1 precision:\t\t\t0.8434237995824635\n",
      "\n",
      "Untuned with tuned manager\n",
      "Sentence length:\tgen / real = \t1.301191818754258\n",
      "Word length:\t\tgen / real =  \t0.9729878985254531\n",
      "rouge-1 precision:\t\t\t0.8805970149253731\n",
      "\n",
      "Untuned\n",
      "Sentence length:\tgen / real = \t1.7774789933315438\n",
      "Word length:\t\tgen / real =  \t0.9785139961235693\n",
      "rouge-1 precision:\t\t\t0.8607843137254902\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_char_ratings(\"Cartman\", tuned_cartman, untuned_cartman, untuned_cartman_m, real_cartman)\n",
    "print_char_ratings(\"Stan\", tuned_stan, untuned_stan, untuned_stan_m, real_stan)\n",
    "print_char_ratings(\"Kyle\", tuned_kyle, untuned_kyle, untuned_kyle_m, real_kyle)\n",
    "print_char_ratings(\"Butters\", tuned_butters, untuned_butters, untuned_butters_m, real_butters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
